# Этап 1. Результаты профилирования

## Содержание

Для нагрузочного тестирования были использованы:

- `wrk2` — [https://github.com/giltene/wrk2](https://github.com/giltene/wrk2)
- `async-profiler` — [https://github.com/jvm-profiling-tools/async-profiler](https://github.com/jvm-profiling-tools/async-profiler)

## Нагрузочное тестирование сервера (Метод PUT)

Для тестирования метода GET нужно заполнить базу значения. Для этого проведём тестирование для метода PUT. 

### CPU

Утилита `wrk2` запускается следующим образом:

```bash
wrk2 -c200 -t4 -d 1m -R 15000 -L -s put.lua http://localhost:8080
```

Утилита `async-profiler` запускается следующим образом:

```bash
./profiler.sh -d 60 -f cpu_put.html 4925
```

Результат работы `wrk2`:

```bash
Running 1m test @ http://localhost:8080
  4 threads and 200 connections
  Thread calibration: mean lat.: 1.173ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.198ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.170ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.197ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.21ms    1.82ms  80.06ms   99.39%
    Req/Sec     3.93k   501.40    24.67k    91.89%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.09ms
 75.000%    1.50ms
 90.000%    1.83ms
 99.000%    2.51ms
 99.900%   30.13ms
 99.990%   65.86ms
 99.999%   72.51ms
100.000%   80.13ms
```

Результат профилирования CPU для метода PUT:

[cpu_put](../cpu_put.html)

Из этих данных следует, что:

- Наша система выдерживает 15000 запросов PUT в секунду
- Такую разницу в 90% и 99.9%, несмотря на асинхронное выполнение выгрузки на диск можно объяснить тем, что некоторое количество времени требуется, для подготовки промежуточно хранилища для выгружаемых данных.
- ~99.9% запросов выполняется менее 2.51 мс, мы получили значительный прирост производительности
- 90% ресурсов процессора использует SelectorThread

    Среди них ~9.8% ресурсов занимает реализованный нами метод entity, который обрабатывает запросы
    также 6.68% ресурсов используют потоки, выполняющие flush

    Запись в сокет остается узким местом системы - 37.5%

- 2.7% ресурсов занимает GarbageCollector, который тоже, вероятно, тормозит обработку запросов

Запись в сокет остается узким местом системы - 37.5%

### Alloc

Запуск утилиты ничем не отличается от запуска для профилирования CPU.

Утилита `async-profiler` запускается следующим образом:

```bash
./profiler.sh -e alloc -d 60 -f alloc_put.html 4925
```

Результат профилирования Alloc для метода PUT:

[alloc_put](../alloc_put.html)

Из этих данных следует, что:

- ~55.5% занимает обработка запроса, в которую входит наша обработка с помощью BasicService. Из этого можно сделать вывод, что где-то треть памяти используется нами для создания буферов для формирования записи, для получения ключа и так далее.
- ~41.1% занимают парсинг запроса, его тела, а также заголовков вместе с методом read в UTF8, то есть формируются строки из байт-буферов.
- Возможно стоит принимать аргументы запроса в неизменном виде, чтобы избежать лишних преобразований
- Также возможно стоит расширить интерфейс класса Record. Добавить некоторый немутируемый ключ, который можно использовать для идентификации во время внутренних манипуляций, чтобы избежать избыточного копирования буферов.

### Lock
Запуск утилиты ничем не отличается от запуска для профилирования CPU.

Утилита `async-profiler` запускается следующим образом:

```bash
./profiler.sh -e lock -d 60 -f alloc_put.html 4925
```

Результат профилирования Alloc для метода PUT:
[lock_put](../lock_put.html)

Из этих данных следует, что:
- Количество блокировок заметно сократилось
- Блокировка теперь происходит только при необходимости синхронизации перед вызовом метода flush


## Нагрузочное тестирование сервера (Метод GET)

Благодаря проведённым тестам база заполнена значения для проведения нагрузочного тестирования метода GET. 

### CPU

Утилита `wrk2` запускается следующим образом:

```bash
wrk2 -c 1 -t 1 -d 1m -R 14970 -L -s get.lua http://localhost:8080
```

Утилита `async-profiler` запускается следующим образом:

```bash
./profiler.sh -d 60 -f cpu_get.html 4925
```

Результат работы `wrk2`:

```bash
Running 1m test @ http://localhost:8080
  4 threads and 200 connections
  Thread calibration: mean lat.: 1.174ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.164ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.183ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.204ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.14ms  602.13us  20.98ms   71.93%
    Req/Sec     3.93k   324.01    10.00k    74.47%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.09ms
 75.000%    1.51ms
 90.000%    1.84ms
 99.000%    2.42ms
 99.900%    5.29ms
 99.990%   14.65ms
 99.999%   18.64ms
100.000%   20.99ms
```

Результат профилирования CPU для метода GET:

[get_cpu.html](../cpu_get.html)

Из этих данных следует, что:

- Наша система выдерживает ~15000 запросов GET в секунду
- ~99.9% запросов выполняется менее 5.29 мс (такая разница объясняется скоростью чтения из памяти и диска)

    Разница между 99.9% и 99.99% может объясняться работа GC, который собирает мусор, приостанавливая ответ на запрос

- 99.4% ресурсов процессора использует SelectorThread

    Среди них 3.8% ресурсов занимает чтение из сокетов информации, запись - 23.57 %

    ~63.76% занимает метод `get`, который мы реализовали. Это связано с большим количеством обращений к диску в SSTable

- 0.79% ресурсов занимает GarbageCollector
- Следующим шагом к оптимизации может асинхронный поиск ключей в SSTable

### Alloc

Запуск утилиты ничем не отличается от запуска для профилирования Alloc.

Утилита `async-profiler` запускается следующим образом:

```bash
./profiler.sh -e alloc -d 60 -f alloc_get.html 4925
```

Результат профилирования Alloc для метода GET:

[alloc_get.html](../alloc_get.html)

Из этих данных следует, что:

- 91.30% занимает обработка запроса нашим методом `get`. Это связано в методом `range` и `hasNext` в нашем DAO. Эти методы являются самыми ресурсоёмкими
- Также возможно стоит расширить интерфейс класса Record. Добавить некоторый немутируемый ключ, который можно использовать для идентификации во время внутренних манипуляций, чтобы избежать избыточного копирования буферов.

### Lock

Запуск утилиты ничем не отличается от запуска для профилирования Alloc.

Утилита `async-profiler` запускается следующим образом:

```bash
./profiler.sh -e lock -d 60 -f lock_get.html 4925
```

Результат профилирования Alloc для метода GET:

[alloc_get.html](../alloc_get.html)

Из этих данных следует, что:

- Блокировки отсутствуют
- Все структуры, хранящиеся в оперативной памяти, конкуренты. Это обеспечивает возможность исключить синхронизацию при реализации метода get.