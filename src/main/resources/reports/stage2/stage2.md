# Оптимизация PUT-запросов

------------------------------------------------------------

## Визуальное сравнение оптимизаций по отчетам wrk2

[put_comparison.html](put_results/wrk/put_comparison.html)

## Описание оптимизаций

* [wrk_put_1_seq.txt](put_results/wrk/wrk_put_1_seq.txt) - исходная последовательная реализация
* [wrk_put_2_no_poll_no_sync.txt](put_results/wrk/wrk_put_2_no_poll_no_sync.txt) - убран мьютекс, захватывающий все тело
  функции `upsert(..)`
* [wrk_put_3_poll41_no_flag.txt](put_results/wrk/wrk_put_3_poll41_no_flag.txt) - добавлен пулл из 1 потока и
  параллельная обработка входящий запросов 4 потоками
* [wrk_put_4_poll41_with_flag.txt](put_results/wrk/wrk_put_4_poll41_with_flag.txt) - добавлен флаг, позволяющий
  контролировать условие "среди потоков попавших в гонку за выполнение функции flush(..) только один займется записью"
* [wrk_put_5_poll41_with_snapshot.txt](put_results/wrk/wrk_put_5_poll41_with_snapshot.txt) - добавлено копирование
  объекта memoryStorage и передача копии в функцию `flush(
  ..)` , чтобы асинхронный `flush(..)` не соревновался с новыми запросами за объект `memoryStorage`
* [wrk_put_6_smart_poll44_switch_careful.txt](put_results/wrk/wrk_put_6_smart_poll44_switch_careful.txt) - добавлен
  подсчет памяти, выделяемой под задачи отправленные асинхронное выполнение в Thread Poll (считаем общий
  memoryConsumption находящийся в очереди к пуллу). Thread Poll из 1-ого потока заменен Thread Poll-ом на 4 потока
* [wrk_put_7_smart_poll44_switch_test_believer.txt](put_results/wrk/wrk_put_7_smart_poll44_switch_test_believer.txt) -
  удален спорный код, лишний раз разделяющий ресурс memoryStorage между потоками выполняющими `flush(..)` и потоками
  производящими записи в объект `memoryStorage`. О том, чем это решение оправдано в финальных выводах

## Сравнение профилей версий

------------------------------------------------------------

### Профилирование cpu

#### Профили

[put sequential cpu profile](put_results/profiling/sequential/put_cpu.html)

[put optimized cpu profile](put_results/profiling/poll/put_cpu.html)

#### Выводы и наблюдения

* Изначально в основной ветке последовательно выполнялось `80%` вычислений на cpu и еще `16%` уходило на ветку сборщика
  мусора, работающую параллельно
* Теперь `26%` асинхронно выполняется в ветке пулла тредов, на `10%` больше стало уходить на работу сборищка мусора
  (предположительно, из-за удаления создаваемых объектов Runnable с захваченным контекстом), а использование
  процессорных ресурсов в ветке обработки входящих запросов и добавлении новых объектов в объект memoryStorage
  сократилось до `50%`

### Профилирование alloc-ов

#### Профили

[put sequential alloc profile](put_results/profiling/sequential/put_alloc.html)

[put optimized alloc profile](put_results/profiling/poll/put_alloc.html)

#### Выводы и наблюдения

* Анологичное с cpu наблюдение - `20%` alloc-ов вынесено в асинхронно выполняющуюся ветку записи данных в файл
* При анализе профиля параллельных alloc-ов также появилось убеждение в том, что доля alloc-ов приходящихся на создание
  лямбд и захвата ими контекста занимает очень мало ресурсов памяти - около`0.69%`, то есть копирование данных там не
  происходит, мы просто передаем ссылки на уже существующие объекты
  (например, при создании того же объекта `memorySnapshot` мы вешаем его ссылку на объект `memoryStorage`, после чего
  ссылку `memoryStorage` вешаем на новый пустой объект `Map`, таким образом избегая копирования, которое происходило бы
  при вызове `memorySnapshot.putAll(memoryStorage)`)
  Исходия из этих рассуждений, предположение сделанное в рассмотрении профилей cpu изменилось, новое предположение -
  большую роль в `10%` добавившихся к ветке сборщика мусора в профиле cpu играют накладные ресурсы на поддержание работы
  нескольких параллельных потоков.

### Профилирование lock-ов

#### Профили

[put sequential lock profile](put_results/profiling/sequential/put_lock.html)

[put optimized lock profile](put_results/profiling/poll/put_lock.html)

#### Выводы и наблюдения

* В последовательной версии почти все lock-и приходятся на функцию `upsert(..)` - `2507/2516`, т.е. `99.64%`
* Если задержать дыхание подобно снайперу в той самой напряженной сцене из голливудского боевика и постараться навести
  курсор мыши на что-то из тех оставшихся `9/2516` lock-ов можно неожиданно заметить в последовательной версии lock
  происходящий в функции `ConcurrentSkipListMap.put(..)`
  Как в полностью залоченной мьютексом функции `LSMDao.upsert(..)` может произойти lock при вставке
  в `ConcurrentListMap`.. Честно говоря, сначала я подумал что это какая-то аномалия присущая операциям
  Concurrent-коллекций, для понимания которой требуется глубокое знание принципов работы этих коллекций на самых низких
  уровнях, но тут я вспомнил, что неплохо бы посмотреть на самый низ стека вызовов.. Так что же в самый нижней ноде
  стека вызовов? Там на самом деле функция `ByteBuffer.compareTo(..)`, которая как я предполагаю работает параллельно.
  Поправьте меня, если я не прав
* В параллельной реализации общее число локов значительно ниже - `28` и `5/28`, т.е.`17%` пойманных lock-ов происходят в
  функции `LSMDao.upsert(..)`, параллельная реализация которой принадлежит мне. И несмотря на то, что доля lock-ов
  происходящих в этой функции на первый взгляд не так велика, на самом если присмотрется, можно заметить, что в
  остальных ветках lock-и в основном происходят при загрузке классов различными библиотечными `ClassLoader-ами`, что как
  мне кажется является не такой серьезной ошибкой при написании параллельного кода. Вообщем, гордиться своими 5-ю
  lock-ами наверное не стоит

# Оптимизация GET-запросов

------------------------------------------------------------

## Визуальное сравнение оптимизаций по отчетам wrk2

[get_comparison.html](get_results/wrk/get_comparison.html)

## Описание оптимизаций

* [wrk_get_1_seq.txt](get_results/wrk/wrk_get_1_seq.txt) - исходная последовательная реализация
* [wrk_get_2_no_sync.txt](get_results/wrk/wrk_get_2_no_sync.txt) - убран мьютекс, захватывающий все тело
  функции `range(..)`

## Сравнение профилей версий

------------------------------------------------------------

### Профилирование cpu

#### Профили

[get sequential cpu profile](get_results/profiling/sequential/get_cpu.html)

[get oprimized cpu profile](get_results/profiling/poll/get_cpu.html)

#### Выводы и наблюдения

* Гораздо больше процессорных ресурсов стала занимать функция `ArrayList.init(..)`:
  `0.72%` в последовательной версии против `28.99%` в параллельной версии. Мне кажется это либо свидетельство имеющегося
  распараллеливания, либо некорректной работы с памятью, точно разобраться не успел.
* Также стоит обратить внимания на пропавшее ресурсы при переходе от функции
  `ConcurrentLinkedDeque.next()` к функции `ConcurrentLinkedDeque.nextNode()`
  потерянные по всей видимости на синхронизацию ресурса при попытке получить к нему доступ разными потоками

### Профилирование alloc-ов

#### Профили

[get sequential alloc profile](get_results/profiling/sequential/get_alloc.html)

[get optimized alloc profile](get_results/profiling/poll/get_alloc.html)

#### Выводы и наблюдения

* Эти профили почти идентичны, что по моему мнению свидетельствуют о том, что с точки зрения потрбления памяти
  распараллеливание реализовано хорошо(именно памяти, насчет семантической надежности и корректности работы сервера при
  различном поведении клиентов у меня возникают вопросы, поскольку я еще не успел понять, насколько хорошо автотесты
  проверяют эту надежность и устойчивость)

### Профилирование lock-ов

#### Профили

[get optimized lock profile](get_results/profiling/sequential/get_lock.html)

[get optimized lock profile](get_results/profiling/poll/get_lock.html)

#### Выводы и наблюдения

* Насколько я могу предположить AppClassLoader.loadClass(..) как-то связан с работой класса `MappedByteBuffer(..)`, в
  частности с подгрузкой данных из файла с таблицей в оперативную память
* Видимо с этого профилирования стоило начать размышления о том, как оптимизировать get-запросы, но к сожалению на это
  не хватило времени

# Общие выводы и замечания

* Несмотря на то, что в ходе оптимизации PUT-запросов был получен хороший количественный результат - среднее время
  ответа уменьшено приблизтельно в `5` раз, а разница между минимальным и максимальным временем обработки запроса
  уменьшена почти в `4.4` раза
* Не уверен что удалось добиться хорошего качественного результата - относительно нового среднего скачки между
  квантилями все равно происходят неравномерно
* Также в ходе разработки не было уделено достаточно времени проверке теоретически возможного сложно отлавливаемого
  некорректного поведения сервера. Наверное можно было бы решения проверять с помощью каких-нибудь верификторов вроде
  NuSMV, чтобы самому не работать интерпретатором параллельных программ с целью поиска возможных редких или не
  отлавливаемых тестами ошибок, но не факт что это позволило бы получить лучший результат
* Надеюсь проходящие автотесты свидетельствуют хотя бы о низкой вероятности возникнования ошибок