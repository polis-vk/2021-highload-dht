## Этап 1. HTTP + storage (deadline 2021-09-29 23:59:59 MSK)
### Задание

Проведите нагрузочное тестирование с помощью [wrk](https://github.com/giltene/wrk2) в **одно соединение**:
* `PUT` запросами на **стабильной** нагрузке (`wrk` должен обеспечивать заданный с помощью `-R` rate запросов)
* `GET` запросами на **стабильной** нагрузке по **наполненной** БД

Приложите полученный консольный вывод `wrk` для обоих видов нагрузки.

Отпрофилируйте приложение (CPU и alloc) под `PUT` и `GET` нагрузкой с помощью [async-profiler](https://github.com/jvm-profiling-tools/async-profiler).
Приложите SVG-файлы FlameGraph `cpu`/`alloc` для `PUT`/`GET` нагрузки.

**Объясните** результаты нагрузочного тестирования и профилирования и приложите **текстовый отчёт** (в Markdown).

### Ход работы

Запустим сервер
```
$ ./gradlew run
```
#### PUT запросы
Проведем нагрузочное тестирование с помощью wrk2 в одно соединение PUT запросами, используя [скрипт](scripts/put.lua):
```
counter = 0

request = function()
   path = "/v0/entity?id=key" .. counter
   wrk.method = "PUT"
   wrk.body = "value" .. counter
   counter = counter + 1
   return wrk.format(nil, path)
end
```

Для этого введем команду:
```
$ wrk2 -c1 -t1 -d3m -R20000 -s scripts/put.lua --latency http://localhost:8080 > wrk-put-report
```

Параллельно начнем профилирование, узнав перед этим PID процесса с помощью `jps`.
```
$ jps
6082 GradleDaemon
6934 Server
8488 GradleDaemon
6953 Jps
6921 GradleWrapperMain
94250 

$ ./profiler.sh -d 30 -f put-cpu.html 6934
$ ./profiler.sh -d 30 -e alloc -f put-alloc.html 6934
```

Результаты [тестирования](put/wrk-put-report)
```
Running 30s test @ http://localhost:8080
  1 threads and 1 connections
  Thread calibration: mean lat.: 536.146ms, rate sampling interval: 1270ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.62s     1.02s    6.26s    74.82%
    Req/Sec    15.73k     9.43k   22.69k    66.67%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    3.89s 
 75.000%    4.29s 
 90.000%    4.57s 
 99.000%    6.25s 
 99.900%    6.27s 
 99.990%    6.27s 
 99.999%    6.27s 
100.000%    6.27s 

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

    2287.615     0.000000          106         1.00
    2473.983     0.100000        32033         1.11
    2603.007     0.200000        64523         1.25
    2772.991     0.300000        95956         1.43
    2926.591     0.400000       127846         1.67
    3893.247     0.500000       159709         2.00
    3981.311     0.550000       175524         2.22
    4050.943     0.600000       191626         2.50
    4116.479     0.650000       208343         2.86
    4198.399     0.700000       223482         3.33
    4288.511     0.750000       239503         4.00
    4341.759     0.775000       247702         4.44
    4382.719     0.800000       255799         5.00
    4423.679     0.825000       263656         5.71
    4476.927     0.850000       271536         6.67
    4521.983     0.875000       279357         8.00
    4550.655     0.887500       283713         8.89
    4567.039     0.900000       287501        10.00
    4583.423     0.912500       291688        11.43
    4599.807     0.925000       295544        13.33
    4616.191     0.937500       299592        16.00
    6164.479     0.943750       301753        17.78
    6172.671     0.950000       303686        20.00
    6180.863     0.956250       305736        22.86
    6193.151     0.962500       307606        26.67
    6205.439     0.968750       309458        32.00
    6213.631     0.971875       310644        35.56
    6217.727     0.975000       311240        40.00
    6225.919     0.978125       312450        45.71
    6234.111     0.981250       313870        53.33
    6238.207     0.984375       314451        64.00
    6242.303     0.985938       315014        71.11
    6246.399     0.987500       315606        80.00
    6246.399     0.989062       315606        91.43
    6250.495     0.990625       316430       106.67
    6254.591     0.992188       317011       128.00
    6254.591     0.992969       317011       142.22
    6258.687     0.993750       317627       160.00
    6258.687     0.994531       317627       182.86
    6258.687     0.995313       317627       213.33
    6262.783     0.996094       318422       256.00
    6262.783     0.996484       318422       284.44
    6262.783     0.996875       318422       320.00
    6262.783     0.997266       318422       365.71
    6262.783     0.997656       318422       426.67
    6266.879     0.998047       319094       512.00
    6266.879     1.000000       319094          inf
#[Mean    =     3615.121, StdDeviation   =     1024.031]
#[Max     =     6262.784, Total count    =       319094]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  476827 requests in 30.00s, 30.47MB read
Requests/sec:  15894.42
Transfer/sec:      1.02MB
```

[Результаты профилирования PUT cpu](put/put-cpu.html)
![](img/put_cpu.png)

[Результаты профилирования PUT alloc](put/put-alloc.html)
![](img/put_alloc.png)

##### Выводы
+ половина запросов обрабатывается меньше чем 3.89s, а половина больше
+ заметна "излишняя" аллокация для иммутабельности буфера, но она требуется для безопасности
+ замечаем работу GC на результате CPU профилирования
+ замечаем, что большую часть ресурсов тратится на flush

#### GET запросы
Теперь проведем тестирование GET запросами через [скрипт](scripts/get.lua):
```
counter = 0

request = function()
   path = "/v0/entity?id=key" .. counter
   wrk.method = "GET"
   counter = counter + 1
   return wrk.format(nil, path)
end
```

введем команду:
```
$ wrk2 -c1 -t1 -d3m -R2000 -s scripts/get.lua --latency http://localhost:8080 > wrk-get-report
```

Также начнем профилирование
```
$ ./profiler.sh -d 60 -f get-cpu.html 6934
$ ./profiler.sh -d 60 -e alloc -f get-alloc.html 6934
```

Результаты [тестирования](get/wrk-get-report)
```
Running 3m test @ http://localhost:8080
  1 threads and 1 connections
  Thread calibration: mean lat.: 3.238ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.34ms    1.34ms  49.89ms   98.35%
    Req/Sec     2.11k   263.41    10.11k    78.96%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.25ms
 75.000%    1.69ms
 90.000%    2.17ms
 99.000%    3.49ms
 99.900%   18.82ms
 99.990%   46.43ms
 99.999%   49.57ms
100.000%   49.92ms

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

       0.062     0.000000            1         1.00
       0.427     0.100000        34043         1.11
       0.679     0.200000        68035         1.25
       0.907     0.300000       102006         1.43
       1.101     0.400000       136174         1.67
       1.254     0.500000       170027         2.00
       1.324     0.550000       187033         2.22
       1.397     0.600000       204058         2.50
       1.474     0.650000       221171         2.86
       1.567     0.700000       238063         3.33
       1.688     0.750000       255078         4.00
       1.759     0.775000       263525         4.44
       1.838     0.800000       272002         5.00
       1.919     0.825000       280547         5.71
       2.000     0.850000       289013         6.67
       2.085     0.875000       297542         8.00
       2.129     0.887500       301791         8.89
       2.175     0.900000       306092        10.00
       2.221     0.912500       310381        11.43
       2.269     0.925000       314560        13.33
       2.323     0.937500       318893        16.00
       2.351     0.943750       320936        17.78
       2.381     0.950000       322990        20.00
       2.415     0.956250       325221        22.86
       2.451     0.962500       327349        26.67
       2.491     0.968750       329419        32.00
       2.517     0.971875       330500        35.56
       2.543     0.975000       331507        40.00
       2.579     0.978125       332553        45.71
       2.633     0.981250       333634        53.33
       2.713     0.984375       334685        64.00
       2.803     0.985938       335223        71.11
       2.983     0.987500       335741        80.00
       3.269     0.989062       336273        91.43
       3.687     0.990625       336804       106.67
       4.291     0.992188       337333       128.00
       4.671     0.992969       337599       142.22
       5.099     0.993750       337865       160.00
       5.703     0.994531       338130       182.86
       6.475     0.995313       338396       213.33
       7.299     0.996094       338662       256.00
       7.855     0.996484       338794       284.44
       8.535     0.996875       338928       320.00
       9.231     0.997266       339060       365.71
       9.999     0.997656       339193       426.67
      11.239     0.998047       339325       512.00
      11.903     0.998242       339392       568.89
      12.887     0.998437       339458       640.00
      14.319     0.998633       339526       731.43
      16.207     0.998828       339591       853.33
      19.247     0.999023       339657      1024.00
      21.295     0.999121       339692      1137.78
      23.215     0.999219       339724      1280.00
      25.423     0.999316       339757      1462.86
      27.439     0.999414       339790      1706.67
      30.047     0.999512       339823      2048.00
      32.447     0.999561       339840      2275.56
      35.487     0.999609       339858      2560.00
      37.599     0.999658       339873      2925.71
      40.479     0.999707       339890      3413.33
      42.175     0.999756       339906      4096.00
      42.943     0.999780       339915      4551.11
      43.871     0.999805       339923      5120.00
      44.223     0.999829       339931      5851.43
      44.895     0.999854       339940      6826.67
      45.695     0.999878       339950      8192.00
      46.047     0.999890       339952      9102.22
      46.431     0.999902       339956     10240.00
      46.783     0.999915       339960     11702.86
      47.551     0.999927       339965     13653.33
      48.127     0.999939       339969     16384.00
      48.319     0.999945       339971     18204.44
      48.639     0.999951       339973     20480.00
      48.767     0.999957       339975     23405.71
      48.863     0.999963       339977     27306.67
      49.023     0.999969       339979     32768.00
      49.055     0.999973       339980     36408.89
      49.183     0.999976       339981     40960.00
      49.215     0.999979       339982     46811.43
      49.311     0.999982       339984     54613.33
      49.311     0.999985       339984     65536.00
      49.343     0.999986       339985     72817.78
      49.343     0.999988       339985     81920.00
      49.567     0.999989       339986     93622.86
      49.567     0.999991       339986    109226.67
      49.727     0.999992       339987    131072.00
      49.727     0.999993       339987    145635.56
      49.727     0.999994       339987    163840.00
      49.887     0.999995       339988    187245.71
      49.887     0.999995       339988    218453.33
      49.887     0.999996       339988    262144.00
      49.887     0.999997       339988    291271.11
      49.887     0.999997       339988    327680.00
      49.919     0.999997       339989    374491.43
      49.919     1.000000       339989          inf
#[Mean    =        1.342, StdDeviation   =        1.341]
#[Max     =       49.888, Total count    =       339989]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  359997 requests in 3.00m, 25.29MB read
  Non-2xx or 3xx responses: 1
Requests/sec:   1999.98
Transfer/sec:    143.87KB
```
[Результаты профилирования GET cpu](get/get-cpu.html)
![](img/get_cpu.png)

[Результаты профилирования GET alloc](get/get-alloc.html)
![](img/get_alloc.png)

##### Выводы
+ примерно поровну делятся ресурсы на работу с сессией и на работу с DAO
+ заметим аналогичную ситуацию с byteBuffer что и с PUT тестированием