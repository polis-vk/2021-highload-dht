# Задание

Обеспечьте потокобезопасность реализации `DAO` с использованием примитивов `java.util.concurrent.*`.
Прокачаться можно с руководством [Java Concurrency in Practice](http://jcip.net/).

Реализуйте **асинхронный flush** MemTable в SSTable, чтобы не блокировать пользовательские запросы.

Сконфигурируйте HTTP сервер, чтобы он обрабатывал запросы с помощью пула из нескольких потоков.

Проведите нагрузочное тестирование с помощью [wrk2](https://github.com/giltene/wrk2) в **несколько соединений** (не меньше 16):
* `PUT` запросами на **стабильной** нагрузке (`wrk2` должен обеспечивать заданный с помощью `-R` rate запросов)
* `GET` запросами на **стабильной** нагрузке по **наполненной** БД

Приложите полученный консольный вывод `wrk2` для обоих видов нагрузки.

Отпрофилируйте приложение (CPU, alloc и **lock**) под `PUT` и `GET` нагрузкой с помощью [async-profiler](https://github.com/jvm-profiling-tools/async-profiler).
Приложите SVG-файлы FlameGraph `cpu`/`alloc`/`lock` для `PUT`/`GET` нагрузки.

**Объясните** результаты нагрузочного тестирования и профилирования и приложите **текстовый отчёт** (в Markdown).

### Report
Когда всё будет готово, присылайте pull request со своей реализацией и проведёнными **оптимизациями** на review.

# Отчет

HTTP сервер сконфигурирован так, что запросы обрабатываются 2-5 потоками.
Проведено нагрузочное тестирование с помощью wrk2 в одно соединение:

### PUT запросами на стабильной нагрузке (wrk должен обеспечивать заданный с помощью -R rate запросов)

Был использован скрипт `put.lua`:
```lua
counter = 0
request = function()
   path = "/v0/entity?id=key" .. counter
   wrk.method = "PUT"
   wrk.body = "value" .. counter
   counter = counter + 1
   return wrk.format(nil, path)
end
```

Нагрузочное тестирование запускалось следующей командой:
```
wrk2 -R5000  -c16 -t16 -d5m -s stage1/scripts/put.lua -L http://localhost:8080 >stage2/report/put-wrk-output
```

Консольный вывод wrk2:
```
Running 5m test @ http://localhost:8080
  16 threads and 16 connections
  Thread calibration: mean lat.: 1.114ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.123ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.133ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.132ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.119ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.127ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.092ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.106ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.118ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.105ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.128ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.112ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.096ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.099ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.113ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.129ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.42ms    2.86ms 154.37ms   98.56%
    Req/Sec   329.53     65.17     4.00k    76.22%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.16ms
 75.000%    1.53ms
 90.000%    1.90ms
 99.000%    6.67ms
 99.900%   43.33ms
 99.990%  107.84ms
 99.999%  147.97ms
100.000%  154.49ms

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

       0.071     0.000000            1         1.00
       0.554     0.100000       145037         1.11
       0.746     0.200000       290082         1.25
       0.901     0.300000       435949         1.43
       1.034     0.400000       580045         1.67
       1.157     0.500000       725848         2.00
       1.218     0.550000       797808         2.22
       1.284     0.600000       870826         2.50
       1.356     0.650000       943113         2.86
       1.436     0.700000      1015197         3.33
       1.526     0.750000      1087496         4.00
       1.576     0.775000      1124354         4.44
       1.629     0.800000      1160500         5.00
       1.686     0.825000      1196323         5.71
       1.750     0.850000      1232970         6.67
       1.821     0.875000      1268821         8.00
       1.861     0.887500      1287038         8.89
       1.905     0.900000      1305011        10.00
       1.956     0.912500      1323405        11.43
       2.015     0.925000      1341355        13.33
       2.087     0.937500      1359472        16.00
       2.129     0.943750      1368541        17.78
       2.177     0.950000      1377507        20.00
       2.235     0.956250      1386620        22.86
       2.309     0.962500      1395592        26.67
       2.419     0.968750      1404789        32.00
       2.509     0.971875      1409248        35.56
       2.663     0.975000      1413726        40.00
       2.915     0.978125      1418257        45.71
       3.309     0.981250      1422791        53.33
       3.941     0.984375      1427308        64.00
       4.391     0.985938      1429584        71.11
       4.999     0.987500      1431847        80.00
       5.911     0.989062      1434110        91.43
       7.283     0.990625      1436371       106.67
       9.231     0.992188      1438644       128.00
      10.551     0.992969      1439770       142.22
      12.175     0.993750      1440902       160.00
      14.319     0.994531      1442036       182.86
      16.831     0.995313      1443170       213.33
      19.727     0.996094      1444306       256.00
      21.439     0.996484      1444875       284.44
      23.215     0.996875      1445432       320.00
      25.503     0.997266      1446002       365.71
      28.095     0.997656      1446569       426.67
      31.103     0.998047      1447132       512.00
      33.023     0.998242      1447415       568.89
      34.975     0.998437      1447700       640.00
      37.375     0.998633      1447984       731.43
      40.095     0.998828      1448264       853.33
      43.679     0.999023      1448548      1024.00
      45.695     0.999121      1448690      1137.78
      47.839     0.999219      1448833      1280.00
      50.047     0.999316      1448972      1462.86
      52.863     0.999414      1449116      1706.67
      56.511     0.999512      1449256      2048.00
      58.847     0.999561      1449326      2275.56
      61.247     0.999609      1449398      2560.00
      64.127     0.999658      1449470      2925.71
      67.711     0.999707      1449539      3413.33
      72.959     0.999756      1449610      4096.00
      76.735     0.999780      1449645      4551.11
      82.175     0.999805      1449680      5120.00
      88.703     0.999829      1449716      5851.43
      95.551     0.999854      1449751      6826.67
     102.143     0.999878      1449787      8192.00
     105.279     0.999890      1449804      9102.22
     108.543     0.999902      1449822     10240.00
     111.679     0.999915      1449840     11702.86
     116.287     0.999927      1449857     13653.33
     121.983     0.999939      1449876     16384.00
     123.839     0.999945      1449884     18204.44
     126.527     0.999951      1449893     20480.00
     129.407     0.999957      1449902     23405.71
     131.455     0.999963      1449910     27306.67
     135.167     0.999969      1449919     32768.00
     136.959     0.999973      1449924     36408.89
     138.623     0.999976      1449928     40960.00
     141.311     0.999979      1449933     46811.43
     142.463     0.999982      1449937     54613.33
     144.127     0.999985      1449941     65536.00
     145.279     0.999986      1449944     72817.78
     146.687     0.999988      1449946     81920.00
     147.071     0.999989      1449948     93622.86
     148.223     0.999991      1449950    109226.67
     149.247     0.999992      1449952    131072.00
     150.143     0.999993      1449954    145635.56
     151.039     0.999994      1449955    163840.00
     151.167     0.999995      1449956    187245.71
     151.679     0.999995      1449957    218453.33
     152.191     0.999996      1449958    262144.00
     152.703     0.999997      1449959    291271.11
     152.703     0.999997      1449959    327680.00
     152.831     0.999997      1449960    374491.43
     152.831     0.999998      1449960    436906.67
     153.855     0.999998      1449962    524288.00
     153.855     0.999998      1449962    582542.22
     153.855     0.999998      1449962    655360.00
     153.855     0.999999      1449962    748982.86
     153.855     0.999999      1449962    873813.33
     153.855     0.999999      1449962   1048576.00
     153.855     0.999999      1449962   1165084.44
     153.855     0.999999      1449962   1310720.00
     154.495     0.999999      1449963   1497965.71
     154.495     1.000000      1449963          inf
#[Mean    =        1.418, StdDeviation   =        2.861]
#[Max     =      154.368, Total count    =      1449963]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  1500001 requests in 5.00m, 95.84MB read
Requests/sec:   5000.03
Transfer/sec:    327.15KB
```

[Результаты профилирования `cpu`](put-cpu.html)
[Результаты профилирования `alloc`](put-alloc.html)
[Результаты профилирования `lock`](put-lock.html)

Выводы:
* Проведенные оптимизации позволили уменьшить время ответа на запрос в сотни раз - среднее уменьшилось с 328.43ms до 1.42ms, stddev с 881.78ms до 2.86ms, максимальное с 6.07s до 154.37ms при таком же rate.
* Наблюдается резкий рост задержки между 99-ым перцентилем и 99.99-ым -- c 43.33ms до 147.97msc -- это связано с тем, что `ConcurrentSkipListMap` добавляет элементы в среднем за `O(log(n))`, где `n` - количество элементов внутри. Количество элементов внутри регулярно меняется, из-за чего получилась такая разница. Также эта оценка всего лишь средняя, и в редких случаях требуется больше времени.
* Согласно графику профилирования `cpu`, чтение запроса из сокета заняло 20.18% (было 13.36%) всего времени, а также 23.38% (было 19.39%) времени ушло на запись ответа в сокет. Эти показатели довольно сложно оптимизировать, так как это часть сетевого взаимодействия, а увеличение процентов говорит о том, что абсолютные значения для всех остальных методов уменьшились.
* Ответы на запросы сервером заняли 4.55% времени, а также 0.99% ушло на `flush` в `FlushService`, а 3.18% - в `ConcurrentSkipListMap.put`. Понятно, что запись во внешнюю память будет всегда сильно дольше записи в оперативную, но это можно пытаться оптимизировать.
* Большая часть процессорного времени -- 43.29% -- уходит на работу `JavaSelector.select`, хочется на это повлиять. 
* Касательно количества аллокаций - в текущей реализации аллокации в `LsmDao.upsert` составляют всего 2.45% (было 10.46%) от общего количества. Однако сильно выделяется 12.20% аллокаций в `Record.of` -- в этом методе целиком копируются 2 байт буффера. Возможной оптимизацией здесь может быть избавление от этого копирования, но в таком случае придется пожертвовать безопасностью.
* Также большое количество аллокаций -- 8.84% тратится на инициализацию строк из массивов байтов. Так как в конце концов БД хранит не строки, а байт буфферы, эту часть можно оптимизировать, и не переводить лишний раз байты в строку, а строку обратно в байты.
* При PUT запросах график профилирования `lock` показывает ровно 0 блокировок.

### GET запросами на стабильной нагрузке по наполненной БД

Был использован скрипт `get.lua`:
```lua
counter = 0
request = function()
	path = "/v0/entity?id=key" .. counter
	wrk.method = "GET"
	counter = counter + 1
	return wrk.format(nil, path)
end
```

Нагрузочное тестирование запускалось следующей командой:
```
wrk2 -R5000  -c16 -t16 -d5m -s stage1/scripts/get.lua -L http://localhost:8080 >stage2/report/get-wrk-output
```

Консольный вывод wrk2:
```
Running 5m test @ http://localhost:8080
  16 threads and 16 connections
  Thread calibration: mean lat.: 4.565ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 4.322ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.674ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 4.125ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.966ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.666ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.632ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.677ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.689ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 4.050ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.882ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.813ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.558ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.568ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 4.050ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 4.437ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     4.20ms   23.22ms 738.30ms   97.69%
    Req/Sec   331.43    129.30     6.30k    94.75%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    1.24ms
 75.000%    1.67ms
 90.000%    2.28ms
 99.000%   95.93ms
 99.900%  325.63ms
 99.990%  633.85ms
 99.999%  717.31ms
100.000%  738.82ms

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

       0.104     0.000000            1         1.00
       0.612     0.100000       145382         1.11
       0.805     0.200000       290371         1.25
       0.962     0.300000       435529         1.43
       1.104     0.400000       580033         1.67
       1.241     0.500000       725992         2.00
       1.312     0.550000       797808         2.22
       1.388     0.600000       870437         2.50
       1.471     0.650000       943272         2.86
       1.563     0.700000      1015523         3.33
       1.670     0.750000      1087813         4.00
       1.732     0.775000      1124159         4.44
       1.800     0.800000      1160240         5.00
       1.878     0.825000      1196484         5.71
       1.973     0.850000      1232727         6.67
       2.097     0.875000      1268813         8.00
       2.177     0.887500      1287039         8.89
       2.277     0.900000      1305189        10.00
       2.413     0.912500      1323186        11.43
       2.641     0.925000      1341323        13.33
       3.171     0.937500      1359344        16.00
       3.681     0.943750      1368404        17.78
       4.463     0.950000      1377494        20.00
       5.759     0.956250      1386533        22.86
       8.239     0.962500      1395590        26.67
      13.175     0.968750      1404653        32.00
      17.119     0.971875      1409185        35.56
      22.639     0.975000      1413718        40.00
      30.911     0.978125      1418250        45.71
      41.375     0.981250      1422786        53.33
      55.647     0.984375      1427314        64.00
      64.543     0.985938      1429578        71.11
      74.111     0.987500      1431846        80.00
      86.719     0.989062      1434109        91.43
     102.143     0.990625      1436375       106.67
     117.951     0.992188      1438636       128.00
     127.615     0.992969      1439772       142.22
     138.623     0.993750      1440905       160.00
     153.343     0.994531      1442043       182.86
     172.159     0.995313      1443168       213.33
     192.639     0.996094      1444303       256.00
     204.287     0.996484      1444866       284.44
     216.831     0.996875      1445434       320.00
     232.447     0.997266      1446001       365.71
     248.959     0.997656      1446565       426.67
     266.751     0.998047      1447136       512.00
     276.223     0.998242      1447417       568.89
     286.975     0.998437      1447700       640.00
     298.751     0.998633      1447985       731.43
     312.831     0.998828      1448265       853.33
     327.423     0.999023      1448554      1024.00
     334.591     0.999121      1448692      1137.78
     345.087     0.999219      1448832      1280.00
     358.655     0.999316      1448972      1462.86
     376.319     0.999414      1449114      1706.67
     404.991     0.999512      1449256      2048.00
     422.655     0.999561      1449326      2275.56
     437.503     0.999609      1449398      2560.00
     461.567     0.999658      1449468      2925.71
     494.591     0.999707      1449540      3413.33
     519.167     0.999756      1449610      4096.00
     536.063     0.999780      1449645      4551.11
     570.879     0.999805      1449680      5120.00
     592.895     0.999829      1449716      5851.43
     609.791     0.999854      1449751      6826.67
     622.591     0.999878      1449787      8192.00
     628.735     0.999890      1449804      9102.22
     634.879     0.999902      1449822     10240.00
     644.095     0.999915      1449840     11702.86
     651.775     0.999927      1449857     13653.33
     658.431     0.999939      1449875     16384.00
     663.551     0.999945      1449884     18204.44
     668.671     0.999951      1449893     20480.00
     673.791     0.999957      1449902     23405.71
     677.375     0.999963      1449910     27306.67
     684.543     0.999969      1449919     32768.00
     692.223     0.999973      1449925     36408.89
     697.343     0.999976      1449929     40960.00
     700.927     0.999979      1449933     46811.43
     705.535     0.999982      1449937     54613.33
     710.143     0.999985      1449941     65536.00
     713.215     0.999986      1449944     72817.78
     714.751     0.999988      1449946     81920.00
     715.775     0.999989      1449948     93622.86
     717.311     0.999991      1449950    109226.67
     719.871     0.999992      1449953    131072.00
     722.943     0.999993      1449954    145635.56
     725.503     0.999994      1449955    163840.00
     727.551     0.999995      1449956    187245.71
     730.111     0.999995      1449957    218453.33
     732.159     0.999996      1449959    262144.00
     732.159     0.999997      1449959    291271.11
     732.159     0.999997      1449959    327680.00
     733.695     0.999997      1449960    374491.43
     733.695     0.999998      1449960    436906.67
     734.719     0.999998      1449961    524288.00
     734.719     0.999998      1449961    582542.22
     734.719     0.999998      1449961    655360.00
     737.279     0.999999      1449962    748982.86
     737.279     0.999999      1449962    873813.33
     737.279     0.999999      1449962   1048576.00
     737.279     0.999999      1449962   1165084.44
     737.279     0.999999      1449962   1310720.00
     738.815     0.999999      1449963   1497965.71
     738.815     1.000000      1449963          inf
#[Mean    =        4.203, StdDeviation   =       23.215]
#[Max     =      738.304, Total count    =      1449963]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  1500002 requests in 5.00m, 104.11MB read
Requests/sec:   5000.01
Transfer/sec:    355.35KB
```

[Результаты профилирования `cpu`](get-cpu.html)
[Результаты профилирования `alloc`](get-alloc.html)
[Результаты профилирования `lock`](get-lock.html)

Выводы:
* Проведенные оптимизации позволили уменьшить время ответа на запрос в сотни раз - среднее уменьшилось с 544.19ms до 4.20ms, stddev с 1.40s до 23.22ms, максимальное с 6.05s до 738.30ms при таком же rate.
* Наблюдается резкий рост задержки между 75-ым перцентилем и 90-ым -- c 68ms до 2.59s -- это связано с тем, что большая часть запросов взаимодействует с быстрой оперативной памятью, а для выполнения некоторых необходимо прочитать данные с диска.
* Согласно графику профилирования `cpu`, чтение запроса из сокета заняло 8.97% (было 5.73%) всего времени, а также 10.76% (было 16.22%) времени ушло на запись ответа в сокет. Эти показатели довольно сложно оптимизировать, так как это часть сетевого взаимодействия.
* Получение ответов на запросы сервером заняло 47.93% общего времени, из которых 28.28% ушло на получение данных из `SSTable` и всего 1.12% на получение данных из `ConcurrentSkipListMap`. Такие большие числа обусловлены тем, что на каждый `GET` запрос производится чтение данных с диска - поиск небходимого `range`.
  Так как мы знаем, что от БД нам на данный момент не нужно ничего, кроме получения значения по ключу - этот момент можно адаптировать под наши нужды и, например, не искать данные на диске, если они уже нашлись в оперативной памяти.
* Также проблему долгих запросов помогло бы решить добавление кеша, однако на данном конкретном тесте все `GET` запросы уникальны, и, следовательно, такая оптимизация только ухудшила бы положение дел.
* При `GET` запросах наибольшее количество аллокаций происходит в итераторах во время поиска следующего элемента -- 57.89%. Это объясняется тем, что БД представляет из себя дерево. При этом сама инициализация итераторов -- метод `LsmDAO.merge` -- составляет всего 15.99% от общего числа аллокаций.
* При `GET` запросах график профилирования `lock` показывает ровно 100% блокировок в `BlockingQueue`, использующейся для асинхронных `flush`.
